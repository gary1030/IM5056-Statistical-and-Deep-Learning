{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B08705012 HW4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape =  (463715, 90)\n",
      "X_subtrain shape =  (417344, 90)\n",
      "X_valid shape =  (46371, 90)\n",
      "Y_subtrain shape =  (417344,)\n",
      "Y_valid shape =  (46371,)\n",
      "X_test shape =  (51630, 90)\n"
     ]
    }
   ],
   "source": [
    "# load packages\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Load data\n",
    "with open('msd_full.pickle', 'rb') as fh1:\n",
    "    msd_data = pickle.load(fh1)\n",
    "\n",
    "doscaling = 1\n",
    "if (doscaling == 1):\n",
    "    xscaler = preprocessing.StandardScaler().fit(msd_data['X_train'])\n",
    "    # standardize feature values\n",
    "    X_train = xscaler.transform(msd_data['X_train'])\n",
    "    X_test = xscaler.transform(msd_data['X_test'])\n",
    "else:\n",
    "    X_train = msd_data['X_train']\n",
    "    X_test = msd_data['X_test']\n",
    "\n",
    "Y_train = msd_data['Y_train']\n",
    "Y_test = msd_data['Y_test'].astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "y_mean = Y_train.mean()\n",
    "Y_train_keep = Y_train.copy()\n",
    "Y_test_keep = Y_test.copy()\n",
    "Y_train = Y_train - y_mean\n",
    "Y_test = Y_test - y_mean\n",
    "\n",
    "\n",
    "# validation is the last 10% of training, subtraining is the first 90% of training\n",
    "nvalid = int(X_train.shape[0] * 0.1)\n",
    "nsubtrain = X_train.shape[0] - nvalid\n",
    "\n",
    "X_subtrain = X_train[0:nsubtrain, :].astype('float32')\n",
    "X_valid = X_train[nsubtrain:, :].astype('float32')\n",
    "Y_subtrain = Y_train[0:nsubtrain].astype('float32')\n",
    "Y_valid = Y_train[nsubtrain:].astype('float32')\n",
    "\n",
    "Y_subtrain_keep = Y_train_keep[0:nsubtrain].astype('float32')\n",
    "Y_valid_keep = Y_train_keep[nsubtrain:].astype('float32')\n",
    "\n",
    "print(\"X_train shape = \", X_train.shape)\n",
    "print(\"X_subtrain shape = \", X_subtrain.shape)\n",
    "print(\"X_valid shape = \", X_valid.shape)\n",
    "print(\"Y_subtrain shape = \", Y_subtrain.shape)\n",
    "print(\"Y_valid shape = \", Y_valid.shape)\n",
    "print(\"X_test shape = \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1\n",
    "使用Training資料訓練一個Ordinary Least Square模型，並進行預測。列出此模型的RMSE與前五個特徵的參數。OLS模型應包含常數項，且不應有任何Regularization。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 coefficients: [ 5.2934217  -2.8868322  -1.5276358   0.06306767 -0.33957994]\n",
      "RMSE =  9.509892\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression(n_jobs=-1)\n",
    "reg.fit(X_subtrain, Y_subtrain_keep)\n",
    "print(\"First 5 coefficients:\", reg.coef_[0:5])\n",
    "y_pred = reg.test(X_test)\n",
    "\n",
    "\n",
    "# squared: bool, default=True\n",
    "# If True returns MSE value, if False returns RMSE value.\n",
    "print(\"RMSE = \", mean_squared_error(Y_test_keep, y_pred, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2\n",
    "\n",
    "- 建構一個有四層Hidden Layer的MLP。\n",
    "- 此模型由輸入層開始，90個Input Features通過線性層轉換為H個Hidden Nodes，\n",
    "- 通過ReLu Activation Function，此為第一層Hidden Layer。\n",
    "- 接著通過下一個線性層與ReLu Activation Function，此為第二層。\n",
    "- 接著下一個線性層與ReLu Activation Function，此為第三層。 \n",
    "- 然後下一個線性層與ReLu Activation Function，此為第四層。\n",
    "- 最後通過一個線性層輸出。 所有Hidden Layer的寬度都為H。\n",
    "\n",
    "令 H= 45, 使用 SGD 更新參數，設 Learning Rate = 0.00001，無 Weight Decay 與 Momentum。畫出模型訓練過程中的 Training 與Validation RMSE，列出 Test RMSE。\n",
    "並討論訓練過程中 Training 與 Validation RMSE 的圖形意義。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "  def __init__(self, X, Y):\n",
    "        self.labels = Y\n",
    "        self.len = X.shape[0]\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "\n",
    "  def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        X = self.X[index]\n",
    "        y = self.Y[index]\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = Dataset(X_train, Y_train)\n",
    "subtrainset = Dataset(X_subtrain, Y_subtrain)\n",
    "validset = Dataset(X_valid, Y_valid)\n",
    "testset = Dataset(X_test, Y_test)\n",
    "\n",
    "trainloader = data.DataLoader(trainset, batch_size=1000, shuffle=True, num_workers=0)\n",
    "subtrainloader = data.DataLoader(subtrainset, batch_size=1000, shuffle=True, num_workers=0)\n",
    "validloader = data.DataLoader(validset, batch_size=10000, shuffle=True, num_workers=0)\n",
    "testloader = data.DataLoader(testset, batch_size=10000, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model(input_size, hidden_size, output_size):\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Linear(input_size, hidden_size),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(hidden_size, hidden_size),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(hidden_size, hidden_size),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(hidden_size, hidden_size),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(hidden_size, output_size)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "net = mlp_model(trainset.X.shape[1], 45, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = net.float()\n",
    "net = net.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.00001, momentum=0, weight_decay=0)\n",
    "loss_func = torch.nn.MSELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Minibatch: 1,000個資料點，更新參數之後稱為經歷了一個Batch。\n",
    "- 當所有 Subtraining 資料已經用來更新過模型參數，稱為經過了一個Epoch。\n",
    "- 每 100 個 Batch 計算一次 Training and Validation RMSE。\n",
    "- 如果 Validation 為歷史最低，則記下當下的模型參數與當時已進行的 Batch 數量，稱為best_step_count。\n",
    "- early_stop 設為 5,000 個 Batch。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livelossplot import PlotLosses\n",
    "import numpy as np\n",
    "\n",
    "def train(net, optimizer, loss_func, trainloader, validloader, epochs=100, patient=5000, model_path='model/result.ckpt', verbose=True):\n",
    "    '''\n",
    "    ### Parameters\n",
    "    - net: model\n",
    "    - optimizer: optimizer (Adam or SGD)\n",
    "    - loss_func: loss function\n",
    "    - trainloader: training data loader\n",
    "    - validloader: validation data loader\n",
    "    - epochs: number of epochs\n",
    "    - patient: number of batches to wait before early stopping\n",
    "    - verbose: print training progress\n",
    "    - model_path: path to save model\n",
    "    '''\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    step_count = 0\n",
    "    best_step_count = 0\n",
    "    interval = 100\n",
    "\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    best_valid_rmse = float(\"inf\")\n",
    "\n",
    "    best_net_state = {}\n",
    "    stop = False\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        if stop:\n",
    "            break\n",
    "        for _, (data, target) in enumerate(trainloader):\n",
    "            step_count += 1\n",
    "            net.train()\n",
    "            target = target.reshape((-1, 1))\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = net(data)\n",
    "            \n",
    "            loss = loss_func(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if step_count % interval == 0:\n",
    "                net.eval()\n",
    "                # calculate training loss with current model\n",
    "                train_loss = 0\n",
    "                for _, (data, target) in enumerate(trainloader):\n",
    "                    target = target.reshape((-1, 1))\n",
    "                    data = data.to(device)\n",
    "                    target = target.to(device)\n",
    "                    output = net(data)\n",
    "                    train_loss += torch.nn.MSELoss(reduction='sum')(output, target).item()\n",
    "                    \n",
    "                train_rmse = np.sqrt(train_loss / len(trainloader.dataset))\n",
    "                train_loss_list.append(train_rmse)      \n",
    "                \n",
    "                # calculate validation loss with current model\n",
    "                valid_loss = 0   \n",
    "                for _, (data, target) in enumerate(validloader):\n",
    "                    target = target.reshape((-1, 1))\n",
    "                    data = data.to(device)\n",
    "                    target = target.to(device)\n",
    "                    output = net(data)\n",
    "                    valid_loss += torch.nn.MSELoss(reduction='sum')(output, target).item()\n",
    "                \n",
    "                valid_rmse = np.sqrt(valid_loss / len(validloader.dataset))\n",
    "                valid_loss_list.append(valid_rmse)\n",
    "\n",
    "                if verbose:\n",
    "                    print(f'Epoch {epoch+1:3} | Step {step_count:6} | Train RMSE {train_rmse:7.4f} | Valid RMSE {valid_rmse:7.4f}')\n",
    "                \n",
    "                if valid_rmse < best_valid_rmse:\n",
    "                    best_valid_rmse = valid_rmse\n",
    "                    best_step_count = step_count\n",
    "                    best_net_state = net.state_dict()\n",
    "                    torch.save(net, model_path)\n",
    "                elif step_count - best_step_count > patient:\n",
    "                    print(\"Early stopping at epoch\", epoch+1)\n",
    "                    stop = True\n",
    "                    break\n",
    "    return net, best_net_state, train_loss_list, valid_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 | Step    100 | Train RMSE  9.5409 | Valid RMSE  9.4925\n",
      "Epoch   1 | Step    200 | Train RMSE  9.1682 | Valid RMSE  9.1105\n",
      "Epoch   1 | Step    300 | Train RMSE  8.9394 | Valid RMSE  8.8871\n",
      "Epoch   1 | Step    400 | Train RMSE  8.8656 | Valid RMSE  8.8165\n",
      "Epoch   2 | Step    500 | Train RMSE  9.0135 | Valid RMSE  8.9647\n",
      "Epoch   2 | Step    600 | Train RMSE  8.7771 | Valid RMSE  8.7416\n",
      "Epoch   2 | Step    700 | Train RMSE  8.7811 | Valid RMSE  8.7575\n",
      "Epoch   2 | Step    800 | Train RMSE  8.9124 | Valid RMSE  8.8904\n",
      "Epoch   3 | Step    900 | Train RMSE  8.7000 | Valid RMSE  8.6853\n",
      "Epoch   3 | Step   1000 | Train RMSE  8.7170 | Valid RMSE  8.7154\n",
      "Epoch   3 | Step   1100 | Train RMSE  8.6597 | Valid RMSE  8.6508\n",
      "Epoch   3 | Step   1200 | Train RMSE  8.6565 | Valid RMSE  8.6505\n",
      "Epoch   4 | Step   1300 | Train RMSE  8.6560 | Valid RMSE  8.6568\n",
      "Epoch   4 | Step   1400 | Train RMSE  8.6398 | Valid RMSE  8.6507\n",
      "Epoch   4 | Step   1500 | Train RMSE  8.6508 | Valid RMSE  8.6687\n",
      "Epoch   4 | Step   1600 | Train RMSE  8.6112 | Valid RMSE  8.6405\n",
      "Epoch   5 | Step   1700 | Train RMSE  8.5925 | Valid RMSE  8.6174\n",
      "Epoch   5 | Step   1800 | Train RMSE  8.6102 | Valid RMSE  8.6405\n",
      "Epoch   5 | Step   1900 | Train RMSE  8.6053 | Valid RMSE  8.6538\n",
      "Epoch   5 | Step   2000 | Train RMSE  8.6065 | Valid RMSE  8.6432\n",
      "Epoch   6 | Step   2100 | Train RMSE  8.6874 | Valid RMSE  8.7313\n",
      "Epoch   6 | Step   2200 | Train RMSE  8.5823 | Valid RMSE  8.6254\n",
      "Epoch   6 | Step   2300 | Train RMSE  8.5806 | Valid RMSE  8.6264\n",
      "Epoch   6 | Step   2400 | Train RMSE  8.5491 | Valid RMSE  8.5952\n",
      "Epoch   6 | Step   2500 | Train RMSE  8.5548 | Valid RMSE  8.6231\n",
      "Epoch   7 | Step   2600 | Train RMSE  8.5632 | Valid RMSE  8.6360\n",
      "Epoch   7 | Step   2700 | Train RMSE  8.5386 | Valid RMSE  8.6160\n",
      "Epoch   7 | Step   2800 | Train RMSE  8.5727 | Valid RMSE  8.6567\n",
      "Epoch   7 | Step   2900 | Train RMSE  8.5555 | Valid RMSE  8.6316\n",
      "Epoch   8 | Step   3000 | Train RMSE  8.5403 | Valid RMSE  8.6324\n",
      "Epoch   8 | Step   3100 | Train RMSE  8.5019 | Valid RMSE  8.5938\n",
      "Epoch   8 | Step   3200 | Train RMSE  8.5058 | Valid RMSE  8.6002\n",
      "Epoch   8 | Step   3300 | Train RMSE  8.4974 | Valid RMSE  8.5966\n",
      "Epoch   9 | Step   3400 | Train RMSE  8.5414 | Valid RMSE  8.6321\n",
      "Epoch   9 | Step   3500 | Train RMSE  8.5301 | Valid RMSE  8.6305\n",
      "Epoch   9 | Step   3600 | Train RMSE  8.4742 | Valid RMSE  8.5808\n",
      "Epoch   9 | Step   3700 | Train RMSE  8.4791 | Valid RMSE  8.5838\n",
      "Epoch  10 | Step   3800 | Train RMSE  8.5280 | Valid RMSE  8.6094\n",
      "Epoch  10 | Step   3900 | Train RMSE  8.4654 | Valid RMSE  8.5707\n",
      "Epoch  10 | Step   4000 | Train RMSE  8.4475 | Valid RMSE  8.5703\n",
      "Epoch  10 | Step   4100 | Train RMSE  8.4863 | Valid RMSE  8.6000\n"
     ]
    }
   ],
   "source": [
    "model, best_net_state, train_loss_list, valid_loss_list = train(net, optimizer=optimizer, loss_func=loss_func, trainloader=subtrainloader, validloader=validloader, epochs=10, model_path=\"model/q2.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, 'RMSE'), Text(0.5, 0, 'number of batches')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "df_loss = pd.DataFrame({\"train_rmse\": train_loss_list, \"valid_rmse\": valid_loss_list})\n",
    "\n",
    "ax = sns.lineplot(data=df_loss, )\n",
    "ax.set(xlabel='number of batches', ylabel='RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, testloader):\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    test_loss_cnt = 0\n",
    "    for _, (data, target) in enumerate(testloader):\n",
    "        target = target.reshape((-1, 1))\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        output = net(data)\n",
    "        loss = loss_func(output, target)\n",
    "        test_loss += loss.item()\n",
    "        test_loss_cnt += data.shape[0]\n",
    "    test_rmse = np.sqrt(test_loss / test_loss_cnt)\n",
    "    print(\"Test RMSE: \", test_rmse)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE:  8.835898347593\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(best_net_state)\n",
    "test(model, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們可以發現"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3\n",
    "使用H = 90與180。無須畫訓練過程的RMSE。列出這兩個Test RMSE。討論H = 45, 90, 180的Test RMSE。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H=90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 | Step    100 | Train RMSE 10.7611 | Valid RMSE  9.7541\n",
      "Epoch   1 | Step    200 | Train RMSE  9.2898 | Valid RMSE  9.0548\n",
      "Epoch   1 | Step    300 | Train RMSE  9.0246 | Valid RMSE  8.8500\n",
      "Epoch   1 | Step    400 | Train RMSE  8.9327 | Valid RMSE  8.7722\n",
      "Epoch   2 | Step    500 | Train RMSE  8.8402 | Valid RMSE  8.8628\n",
      "Epoch   2 | Step    600 | Train RMSE  8.8151 | Valid RMSE  8.7924\n",
      "Epoch   2 | Step    700 | Train RMSE  8.7936 | Valid RMSE  8.7567\n",
      "Epoch   2 | Step    800 | Train RMSE  8.7721 | Valid RMSE  8.8156\n",
      "Epoch   3 | Step    900 | Train RMSE  8.7489 | Valid RMSE  8.6336\n",
      "Epoch   3 | Step   1000 | Train RMSE  8.6488 | Valid RMSE  8.6681\n",
      "Epoch   3 | Step   1100 | Train RMSE  8.7156 | Valid RMSE  8.5951\n",
      "Epoch   3 | Step   1200 | Train RMSE  8.7233 | Valid RMSE  8.6149\n",
      "Epoch   4 | Step   1300 | Train RMSE  8.6589 | Valid RMSE  8.7029\n",
      "Epoch   4 | Step   1400 | Train RMSE  8.6371 | Valid RMSE  8.5970\n",
      "Epoch   4 | Step   1500 | Train RMSE  8.6702 | Valid RMSE  8.6921\n",
      "Epoch   4 | Step   1600 | Train RMSE  8.6188 | Valid RMSE  8.5876\n",
      "Epoch   5 | Step   1700 | Train RMSE  8.6000 | Valid RMSE  8.6403\n",
      "Epoch   5 | Step   1800 | Train RMSE  8.6208 | Valid RMSE  8.6067\n",
      "Epoch   5 | Step   1900 | Train RMSE  8.5693 | Valid RMSE  8.5841\n",
      "Epoch   5 | Step   2000 | Train RMSE  8.5411 | Valid RMSE  8.6661\n",
      "Epoch   6 | Step   2100 | Train RMSE  8.5702 | Valid RMSE  8.5579\n",
      "Epoch   6 | Step   2200 | Train RMSE  8.4980 | Valid RMSE  8.5407\n",
      "Epoch   6 | Step   2300 | Train RMSE  8.5882 | Valid RMSE  8.5543\n",
      "Epoch   6 | Step   2400 | Train RMSE  8.5027 | Valid RMSE  8.5823\n",
      "Epoch   6 | Step   2500 | Train RMSE  8.5073 | Valid RMSE  8.5758\n",
      "Epoch   7 | Step   2600 | Train RMSE  8.4370 | Valid RMSE  8.5590\n",
      "Epoch   7 | Step   2700 | Train RMSE  8.5234 | Valid RMSE  8.5350\n",
      "Epoch   7 | Step   2800 | Train RMSE  8.4635 | Valid RMSE  8.5457\n",
      "Epoch   7 | Step   2900 | Train RMSE  8.5175 | Valid RMSE  8.6954\n",
      "Epoch   8 | Step   3000 | Train RMSE  8.4138 | Valid RMSE  8.5585\n",
      "Epoch   8 | Step   3100 | Train RMSE  8.4716 | Valid RMSE  8.5550\n",
      "Epoch   8 | Step   3200 | Train RMSE  8.4394 | Valid RMSE  8.5111\n",
      "Epoch   8 | Step   3300 | Train RMSE  8.4522 | Valid RMSE  8.5399\n",
      "Epoch   9 | Step   3400 | Train RMSE  8.4035 | Valid RMSE  8.5797\n",
      "Epoch   9 | Step   3500 | Train RMSE  8.4074 | Valid RMSE  8.5387\n",
      "Epoch   9 | Step   3600 | Train RMSE  8.4257 | Valid RMSE  8.5483\n",
      "Epoch   9 | Step   3700 | Train RMSE  8.4340 | Valid RMSE  8.4953\n",
      "Epoch  10 | Step   3800 | Train RMSE  8.3679 | Valid RMSE  8.5646\n",
      "Epoch  10 | Step   3900 | Train RMSE  8.3862 | Valid RMSE  8.5504\n",
      "Epoch  10 | Step   4000 | Train RMSE  8.3859 | Valid RMSE  8.5327\n",
      "Epoch  10 | Step   4100 | Train RMSE  8.3607 | Valid RMSE  8.5197\n",
      "Test RMSE:  8.932279437592602\n"
     ]
    }
   ],
   "source": [
    "net = mlp_model(trainset.X.shape[1], 90, 1)\n",
    "net = net.to(device)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.00001, momentum=0, weight_decay=0)\n",
    "model, best_net_state, _, _ = train(net, optimizer=optimizer, loss_func=loss_func, sse_func=sse_func, trainloader=subtrainloader, validloader=validloader, epochs=10, verbose=False, model_path=\"model/q3_90.ckpt\")\n",
    "model.load_state_dict(best_net_state)\n",
    "test(model, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H=180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 | Step    100 | Train RMSE 10.5138 | Valid RMSE  9.3916\n",
      "Epoch   1 | Step    200 | Train RMSE  9.1842 | Valid RMSE  8.9980\n",
      "Epoch   1 | Step    300 | Train RMSE  8.9765 | Valid RMSE  8.9554\n",
      "Epoch   1 | Step    400 | Train RMSE  8.9497 | Valid RMSE  8.7366\n",
      "Epoch   2 | Step    500 | Train RMSE  8.8426 | Valid RMSE  8.9102\n",
      "Epoch   2 | Step    600 | Train RMSE  8.8214 | Valid RMSE  8.6708\n",
      "Epoch   2 | Step    700 | Train RMSE  8.7276 | Valid RMSE  8.6723\n",
      "Epoch   2 | Step    800 | Train RMSE  8.7338 | Valid RMSE  8.6348\n",
      "Epoch   3 | Step    900 | Train RMSE  8.6806 | Valid RMSE  8.6224\n",
      "Epoch   3 | Step   1000 | Train RMSE  8.7374 | Valid RMSE  8.7168\n",
      "Epoch   3 | Step   1100 | Train RMSE  8.6523 | Valid RMSE  8.6241\n",
      "Epoch   3 | Step   1200 | Train RMSE  8.6531 | Valid RMSE  8.5750\n",
      "Epoch   4 | Step   1300 | Train RMSE  8.5753 | Valid RMSE  8.6483\n",
      "Epoch   4 | Step   1400 | Train RMSE  8.5541 | Valid RMSE  8.5648\n",
      "Epoch   4 | Step   1500 | Train RMSE  8.5702 | Valid RMSE  8.5461\n",
      "Epoch   4 | Step   1600 | Train RMSE  8.5832 | Valid RMSE  8.5530\n",
      "Epoch   5 | Step   1700 | Train RMSE  8.5379 | Valid RMSE  8.5353\n",
      "Epoch   5 | Step   1800 | Train RMSE  8.4878 | Valid RMSE  8.5694\n",
      "Epoch   5 | Step   1900 | Train RMSE  8.5644 | Valid RMSE  8.5528\n",
      "Epoch   5 | Step   2000 | Train RMSE  8.5167 | Valid RMSE  8.7164\n",
      "Epoch   6 | Step   2100 | Train RMSE  8.4955 | Valid RMSE  8.5638\n",
      "Epoch   6 | Step   2200 | Train RMSE  8.4127 | Valid RMSE  8.5640\n",
      "Epoch   6 | Step   2300 | Train RMSE  8.4247 | Valid RMSE  8.5319\n",
      "Epoch   6 | Step   2400 | Train RMSE  8.4283 | Valid RMSE  8.5031\n",
      "Epoch   6 | Step   2500 | Train RMSE  8.4658 | Valid RMSE  8.4920\n",
      "Epoch   7 | Step   2600 | Train RMSE  8.3511 | Valid RMSE  8.5324\n",
      "Epoch   7 | Step   2700 | Train RMSE  8.3930 | Valid RMSE  8.5249\n",
      "Epoch   7 | Step   2800 | Train RMSE  8.3523 | Valid RMSE  8.4903\n",
      "Epoch   7 | Step   2900 | Train RMSE  8.4089 | Valid RMSE  8.4679\n",
      "Epoch   8 | Step   3000 | Train RMSE  8.2564 | Valid RMSE  8.5413\n",
      "Epoch   8 | Step   3100 | Train RMSE  8.2846 | Valid RMSE  8.5379\n",
      "Epoch   8 | Step   3200 | Train RMSE  8.3152 | Valid RMSE  8.5278\n",
      "Epoch   8 | Step   3300 | Train RMSE  8.3446 | Valid RMSE  8.5026\n",
      "Epoch   9 | Step   3400 | Train RMSE  8.2332 | Valid RMSE  8.4962\n",
      "Epoch   9 | Step   3500 | Train RMSE  8.2040 | Valid RMSE  8.8326\n",
      "Epoch   9 | Step   3600 | Train RMSE  8.3015 | Valid RMSE  8.6075\n",
      "Epoch   9 | Step   3700 | Train RMSE  8.2779 | Valid RMSE  8.6508\n",
      "Epoch  10 | Step   3800 | Train RMSE  8.1907 | Valid RMSE  8.5042\n",
      "Epoch  10 | Step   3900 | Train RMSE  8.1650 | Valid RMSE  8.6769\n",
      "Epoch  10 | Step   4000 | Train RMSE  8.1938 | Valid RMSE  8.5764\n",
      "Epoch  10 | Step   4100 | Train RMSE  8.2163 | Valid RMSE  8.5089\n",
      "Test RMSE:  8.892889840738988\n"
     ]
    }
   ],
   "source": [
    "net = mlp_model(trainset.X.shape[1], 180, 1)\n",
    "net = net.to(device)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.00001, momentum=0, weight_decay=0)\n",
    "model, best_net_state, _, _ = train(net, optimizer=optimizer, loss_func=loss_func, sse_func=sse_func, trainloader=subtrainloader, validloader=validloader, epochs=10, verbose=False, model_path=\"model/q3_180.ckpt\")\n",
    "model.load_state_dict(best_net_state)\n",
    "test(model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4\n",
    "使用Q2的模型設定，考慮 H = 45, 90, 180與Weight Decay = 0.1, 0.2, 0.4的所有組合。模型估計後做表整理Test RMSE。討論H的選擇應為多少較合理?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_list = [45, 90, 180]\n",
    "weight_decay_list = [0.1, 0.2, 0.4]\n",
    "\n",
    "for h in H_list:\n",
    "    for weight_decay in weight_decay_list:\n",
    "        net = mlp_model(trainset.X.shape[1], h, 1)\n",
    "        net = net.to(device)\n",
    "        optimizer = torch.optim.SGD(net.parameters(), lr=0.00001, momentum=0, weight_decay=weight_decay)\n",
    "        model, best_net_state, _, _ = train(net, optimizer=optimizer, loss_func=loss_func, sse_func=sse_func, trainloader=subtrainloader, validloader=validloader, epochs=10, verbose=False model_path=f\"model/q4_{h}_{weight_decay}.ckpt\")\n",
    "        model.load_state_dict(best_net_state)\n",
    "        print(\"H:\", h, \"weight_decay:\", weight_decay)\n",
    "        test(model, testloader)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5\n",
    "建構一個有Dropout的四層Hidden Layer的MLP。\n",
    "- 第一層由90個Input Features通過線性層轉換為H個Hidden Nodes\n",
    "- 通過ReLu Activation Function\n",
    "- 對Hidden Unit Dropout，機率為0.5。\n",
    "- 後面各Hidden Lyaer均在ReLu後有Dropout，機率皆為0.5。\n",
    "- 最後通過一個線性層輸出。所有Hidden Layer的寬度都為H。\n",
    "\n",
    "- 令 H= 90, 使用Adaptive Moment Estimation (Adam)更新參數\n",
    "- 設Learning Rate = 0.001，無Weight Decay與Momentum。\n",
    "- 畫出模型訓練過程中的Training與Validation RMSE，列出Test RMSE。 並討論訓練過程中Training與Validation RMSE的圖形意義。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model_with_dropout(input_size, H, output_size, dropout_rate):\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Linear(input_size, H),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Dropout(dropout_rate),\n",
    "        torch.nn.Linear(H, H),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Dropout(dropout_rate),\n",
    "        torch.nn.Linear(H, H),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Dropout(dropout_rate),\n",
    "        torch.nn.Linear(H, H),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Dropout(dropout_rate),\n",
    "        torch.nn.Linear(H, output_size)\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = mlp_model_with_dropout(trainset.X.shape[1], 90, 1, 0.5)\n",
    "net = net.float().to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001, momentum=0, weight_decay=0)\n",
    "loss_func = torch.nn.MSELoss(redution='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, best_net_state, train_loss_list, valid_loss_list = train(net, optimizer=optimizer, loss_func=loss_func, trainloader=subtrainloader, validloader=validloader, epochs=10, model_path=\"model/q5_90.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loss = pd.DataFrame({\"train_rmse\": train_loss_list, \"valid_rmse\": valid_loss_list})\n",
    "\n",
    "ax = sns.lineplot(data=df_loss, )\n",
    "ax.set(xlabel='number of batches', ylabel='RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(best_net_state)\n",
    "test(model, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6\n",
    "使用上題的模型，考慮H = 20, 180, 360。 討論H = 20, 45, 180, 360的Test RMSE。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = mlp_model_with_dropout(trainset.X.shape[1], 20, 1, 0.5)\n",
    "net = net.float().to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001, momentum=0, weight_decay=0)\n",
    "model, best_net_state, _, _ = train(net, optimizer=optimizer, loss_func=loss_func, trainloader=subtrainloader, validloader=validloader, epochs=10, verbose=False, model_path=\"model/q6_20.ckpt\")\n",
    "model.load_state_dict(best_net_state)\n",
    "test(model, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = mlp_model_with_dropout(trainset.X.shape[1], 180, 1, 0.5)\n",
    "net = net.float().to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001, momentum=0, weight_decay=0)\n",
    "model, best_net_state, _, _ = train(net, optimizer=optimizer, loss_func=loss_func, trainloader=subtrainloader, validloader=validloader, epochs=10, verbose=False, model_path=\"model/q6_180.ckpt\")\n",
    "model.load_state_dict(best_net_state)\n",
    "test(model, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H = 360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = mlp_model_with_dropout(trainset.X.shape[1], 360, 1, 0.5)\n",
    "net = net.float().to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001, momentum=0, weight_decay=0)\n",
    "model, best_net_state, _, _ = train(net, optimizer=optimizer, loss_func=loss_func, trainloader=subtrainloader, validloader=validloader, epochs=10, verbose=False, model_path=\"model/q6_360.ckpt\")\n",
    "model.load_state_dict(best_net_state)\n",
    "test(model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7\n",
    "\n",
    "我們前面的小題皆是使用SSE，也就是L2 Loss。一個改善模型訓練的方式是使用多種類似的Loss，以線性組合的方式建構Loss Function。請使用Q5中的MLP with Dropout模型 (H = 90)，並以L2 + L1 Loss訓練模型。這個Loss的定義如下:\n",
    "\n",
    "$$\n",
    "loss(\\mathbf{y}, \\hat{\\mathbf{y}}) = z \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 + (1 - z) \\sum_{i = 1}^n | y_i - \\hat{y}_i |,\n",
    "$$\n",
    "其中z為實數且$0 <=z <= 1$。\n",
    "\n",
    "使用z = 0.5。並以Adam訓練模型。畫出Training and Validation RMSE，並報告Test RMSE。注意這裡繪圖時應使用RMSE而不是這個特殊的Loss。\n",
    "\n",
    "另外，使用z = 0.0, 0.1, 0.9, 1.0訓練模型(不須提供訓練過程的Loss圖形)，統整各個z值下的Test RMSE並討論。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customized_loss_func(output, target):\n",
    "    loss = torch.mean(torch.abs(output - target))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q8 \n",
    "考慮另一個比較特別的Loss Function\n",
    "\n",
    "$$\n",
    "qloss(\\mathbf{y}, \\hat{\\mathbf{y}}) = \\sum_{i=1}^n \\{ q (y_i - \\hat{y}_i)_+ + (1 - q) (\\hat{y}_i - y_i)_+ \\},\n",
    "$$\n",
    "其中q為參數且$0<=q<=1$，而$(y_i - \\hat{y}_i)_+$是取正值的意思。也就是說如果$(y_i - \\hat{y}_i) > 0$，則$(y_i - \\hat{y}_i)_+ = y_i - \\hat{y}_i$，否則$(y_i - \\hat{y}_i)_+ = 0$。\n",
    "\n",
    "令模型的Loss為$z \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 + (1 - z) \\sum_{i=1}^n \\{ 0.5 (y_i - \\hat{y}_i)_+ + 0.5 (\\hat{y}_i - y_i)_+ \\} $。請使用Q5中的MLP with Dropout模型(H = 90)，令z = 0。並以Adam訓練模型。畫出Training and Validation RMSE，並報告Test RMSE。注意這裡繪圖時應使用RMSE而不是這個特殊的Loss。\n",
    "\n",
    "另外，使用z = 0.1, 0.5, 0.9, 1.0訓練模型(不須提供訓練過程的Loss圖形)，統整各個z值下的Test RMSE並討論。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b881d7d647b99d6d14eaae6204912b6a54644d55796571ff1cc40dd37efe80a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
